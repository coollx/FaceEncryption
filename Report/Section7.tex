\section{Discussion and Conclusion}

Our application demonstrates how adversarial attacks can protect the privacy of facial image sharing. By applying perturbations to the input images, our application was able to cause the machine learning model to make errors, potentially protecting the identity of the individuals depicted in the images. This is an important consideration when sharing images online, as there are often concerns regarding personal privacy and the possibility of malicious actors gaining access to sensitive information.

\section{Ethical Considerations}

The ethical considerations of this project are related to the malicious usage of the targeted-attack application. Specifically, there is a concern that the model could be used to reidentify an individual's photos and attach them to another person's identity, potentially leading to serious consequences for the misidentified individual. This type of malicious use could lead to reputational harm, financial harm, or other types of harm to the individual who is falsely identified. It is important that measures are put in place to prevent this type of misuse, and that appropriate safeguards are in place to protect the privacy and security of individuals whose photos may be used in the model.

\section{Future Work}

There are multiple possible future directions for this project's development. One option is to explore the use of more realistic attack scenarios, such as blackbox attacks, which more closely reflect the types of real-world threats that individuals and organizations may face. This may include the development of new techniques for evaluating the robustness of the model under various attack scenarios, as well as the exploration of new algorithms and methods for enhancing the model's performance in these scenarios.

The development of a server-client application that processes photos on the server, rather than on the user's device, is another avenue for future research. This could mitigate some of the ethical concerns associated with the malicious use of the targeted-attack application, as it would permit greater control and oversight over the model's application.

\appendix

\section{Contributions}

XiangLi and Jiaxun took the lead in the modelling and live demo. 

Bowen took the lead in the report.

